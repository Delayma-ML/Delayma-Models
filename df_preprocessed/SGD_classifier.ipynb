{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.2)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vartika\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\Vartika\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomState(MT19937) at 0x1AFDDFFF540"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# fix a random seed\n",
    "np.random.seed(42)\n",
    "import sklearn\n",
    "sklearn.utils.check_random_state(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vartika\\Documents\\GitHub\\Delayma-Models\n",
      "C:\\Users\\Vartika\\Documents\\GitHub\\Delayma-Models\\df_preprocessed\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "data = pd.read_csv('Datasets/df_preprocessed.csv')\n",
    "data.head()\n",
    "%cd df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK',\n",
      "       'OP_UNIQUE_CARRIER', 'DEST', 'DEP_DELAY', 'CRS_ELAPSED_TIME',\n",
      "       'DISTANCE', 'CRS_DEP_M', 'CRS_ARR_M', 'Temperature', 'Dew Point',\n",
      "       'Humidity', 'Wind', 'Wind Speed', 'Wind Gust', 'Pressure', 'sch_dep',\n",
      "       'sch_arr', 'TAXI_OUT', 'Cloudy', 'Windy', 'Fair', 'Rain', 'Fog',\n",
      "       'Drizzle', 'Snow', 'Wintry Mix', 'Freezing Rain', 'MONTH_sin',\n",
      "       'MONTH_cos', 'DAY_OF_MONTH_sin', 'DAY_OF_MONTH_cos', 'DAY_OF_WEEK_sin',\n",
      "       'DAY_OF_WEEK_cos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print columns\n",
    "print(data.columns)\n",
    "# drop MONTH, DAY_OF_MONTH, DAY_OF_WEEK\n",
    "data.drop(['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "    'tol' : [1e-5, 1e-4],\n",
    "    'loss' : ['hinge', 'modified_huber', 'perceptron'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: l2, tol: 0.0001, loss: modified_huber, Accuracy: 0.8455933379597502, Recall: 0.029077117572692796, Precision: 0.15862068965517243, F1: 0.04914529914529915\n",
      "Penalty: l2, tol: 0.0001, loss: perceptron, Accuracy: 0.8429909784871616, Recall: 0.03034134007585335, Precision: 0.14814814814814814, F1: 0.05036726128016789\n",
      "Penalty: elasticnet, tol: 1e-05, loss: hinge, Accuracy: 0.8594725884802221, Recall: 0.008849557522123894, Precision: 0.21212121212121213, F1: 0.01699029126213592\n",
      "Penalty: elasticnet, tol: 1e-05, loss: modified_huber, Accuracy: 0.19083969465648856, Recall: 0.9683944374209861, Precision: 0.14172062904717853, F1: 0.24725629438347316\n",
      "Penalty: elasticnet, tol: 1e-05, loss: perceptron, Accuracy: 0.8568702290076335, Recall: 0.012642225031605562, Precision: 0.18518518518518517, F1: 0.023668639053254437\n",
      "Penalty: elasticnet, tol: 0.0001, loss: hinge, Accuracy: 0.25763358778625955, Recall: 0.9279393173198482, Precision: 0.14810330912025826, F1: 0.25543761962763173\n",
      "Penalty: elasticnet, tol: 0.0001, loss: modified_huber, Accuracy: 0.8565232477446217, Recall: 0.011378002528445006, Precision: 0.16666666666666666, F1: 0.021301775147928994\n",
      "Penalty: elasticnet, tol: 0.0001, loss: perceptron, Accuracy: 0.854441360166551, Recall: 0.012642225031605562, Precision: 0.14705882352941177, F1: 0.023282887077997673\n",
      "Penalty: l1, tol: 1e-05, loss: hinge, Accuracy: 0.8357043719639139, Recall: 0.16308470290771176, Precision: 0.3115942028985507, F1: 0.21410788381742737\n",
      "Penalty: l1, tol: 1e-05, loss: modified_huber, Accuracy: 0.857911172796669, Recall: 0.040455120101137804, Precision: 0.34782608695652173, F1: 0.072480181200453\n",
      "Penalty: l1, tol: 1e-05, loss: perceptron, Accuracy: 0.8239070090215128, Recall: 0.20986093552465235, Precision: 0.29856115107913667, F1: 0.2464736451373423\n",
      "Penalty: l1, tol: 0.0001, loss: hinge, Accuracy: 0.8554823039555864, Recall: 0.02654867256637168, Precision: 0.25, F1: 0.048\n",
      "Penalty: l1, tol: 0.0001, loss: modified_huber, Accuracy: 0.8558292852185982, Recall: 0.01643489254108723, Precision: 0.19696969696969696, F1: 0.030338389731621937\n",
      "Penalty: l1, tol: 0.0001, loss: perceptron, Accuracy: 0.857911172796669, Recall: 0.007585335018963337, Precision: 0.15, F1: 0.01444043321299639\n",
      "Penalty: l2, tol: 1e-05, loss: hinge, Accuracy: 0.8584316446911867, Recall: 0.025284450063211124, Precision: 0.3076923076923077, F1: 0.04672897196261682\n",
      "Penalty: l2, tol: 1e-05, loss: modified_huber, Accuracy: 0.850971547536433, Recall: 0.020227560050568902, Precision: 0.16, F1: 0.03591470258136926\n",
      "Penalty: l2, tol: 1e-05, loss: perceptron, Accuracy: 0.29875086745315754, Recall: 0.8862199747155499, Precision: 0.150655491081023, F1: 0.257531227038942\n",
      "Penalty: l2, tol: 0.0001, loss: hinge, Accuracy: 0.8584316446911867, Recall: 0.0050568900126422255, Precision: 0.12121212121212122, F1: 0.00970873786407767\n",
      "Penalty: l2, tol: 0.0001, loss: modified_huber, Accuracy: 0.8455933379597502, Recall: 0.029077117572692796, Precision: 0.15862068965517243, F1: 0.04914529914529915\n",
      "Penalty: l2, tol: 0.0001, loss: perceptron, Accuracy: 0.8429909784871616, Recall: 0.03034134007585335, Precision: 0.14814814814814814, F1: 0.05036726128016789\n",
      "Penalty: elasticnet, tol: 1e-05, loss: hinge, Accuracy: 0.8594725884802221, Recall: 0.008849557522123894, Precision: 0.21212121212121213, F1: 0.01699029126213592\n",
      "Penalty: elasticnet, tol: 1e-05, loss: modified_huber, Accuracy: 0.19083969465648856, Recall: 0.9683944374209861, Precision: 0.14172062904717853, F1: 0.24725629438347316\n",
      "Penalty: elasticnet, tol: 1e-05, loss: perceptron, Accuracy: 0.8568702290076335, Recall: 0.012642225031605562, Precision: 0.18518518518518517, F1: 0.023668639053254437\n",
      "Penalty: elasticnet, tol: 0.0001, loss: hinge, Accuracy: 0.25763358778625955, Recall: 0.9279393173198482, Precision: 0.14810330912025826, F1: 0.25543761962763173\n",
      "Penalty: elasticnet, tol: 0.0001, loss: modified_huber, Accuracy: 0.8565232477446217, Recall: 0.011378002528445006, Precision: 0.16666666666666666, F1: 0.021301775147928994\n",
      "Penalty: elasticnet, tol: 0.0001, loss: perceptron, Accuracy: 0.854441360166551, Recall: 0.012642225031605562, Precision: 0.14705882352941177, F1: 0.023282887077997673\n"
     ]
    }
   ],
   "source": [
    "for i in hyperparameters['penalty']:\n",
    "    for j in hyperparameters['tol']:\n",
    "        for k in hyperparameters['loss']:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data, data['DEP_DELAY'], test_size=0.2, random_state=42)            \n",
    "            if i == 'l1' or i == 'l2':\n",
    "                clf = SGDClassifier(penalty=i, tol=j, loss=k, alpha=0.0001)\n",
    "            else:\n",
    "                clf = SGDClassifier(penalty=i, tol=j, loss=k, alpha=0.0001, l1_ratio=0.15)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            print(f\"Penalty: {i}, tol: {j}, loss: {k}, Accuracy: {accuracy}, Recall: {recall}, Precision: {precision}, F1: {f1}\")\n",
    "            # write into a csv file for saving results \n",
    "            with open('SGD_results.csv', 'a') as f:\n",
    "                hyper_param = \"{Penalty = \" + str(i) + \" Tolerance = \" + str(j) + \" Loss = \" + str(k) + \"}\"\n",
    "                f.write(f\"SGD Classifier, 80-20, {accuracy*100}, {recall}, {precision}, {f1_score}, {hyper_param}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
